{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9927ebe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, KFold \n",
    "from sksurv.util import Surv\n",
    "from sklearn.impute import SimpleImputer\n",
    "import scipy.stats as stats\n",
    "from sksurv.ensemble import RandomSurvivalForest, GradientBoostingSurvivalAnalysis, ExtraSurvivalTrees\n",
    "from sksurv.metrics import concordance_index_ipcw\n",
    "from sklearn.utils.discovery import all_estimators\n",
    "from tqdm import tqdm\n",
    "from sksurv.linear_model import CoxPHSurvivalAnalysis, CoxnetSurvivalAnalysis, IPCRidge\n",
    "from sksurv.tree import SurvivalTree, ExtraSurvivalTree\n",
    "from sksurv.svm import MinlipSurvivalAnalysis\n",
    "from sklearn.inspection import permutation_importance\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2fb99cd",
   "metadata": {},
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0fcdfaf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clinical data\n",
    "df_clinical_train = pd.read_csv('data/X_train/clinical_train.csv')\n",
    "df_clinical_test = pd.read_csv('data/X_test/clinical_test.csv')\n",
    "\n",
    "# Molecular data\n",
    "df_molecular_train = pd.read_csv('data/X_train/molecular_train.csv')\n",
    "df_molecular_test = pd.read_csv('data/X_test/molecular_test.csv')\n",
    "\n",
    "df_traget_train = pd.read_csv('data/target_train.csv')\n",
    "df_traget_train['OS_YEARS'] = pd.to_numeric(df_traget_train['OS_YEARS'], errors='coerce')\n",
    "df_traget_train['OS_STATUS'] = df_traget_train['OS_STATUS'].astype(bool)\n",
    "df_traget_train.dropna(subset=['OS_STATUS','OS_YEARS'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fab3b035",
   "metadata": {},
   "source": [
    "## A. Clinical data engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9ef5d36",
   "metadata": {},
   "source": [
    "We engineer a feature by calculating ratios relative to WBC and defining specific disease burden indicators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cc10a902",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clinical_ratio(clinical_data):\n",
    "    BM_BLAST = clinical_data['BM_BLAST']\n",
    "    WBC = clinical_data['WBC']\n",
    "    ANC = clinical_data['ANC']\n",
    "    MONOCYTES = clinical_data['MONOCYTES']\n",
    "    HB = clinical_data['HB']\n",
    "    PLT = clinical_data['PLT']\n",
    "\n",
    "    epsilon = 1e-6\n",
    "\n",
    "    ANC_WBC = ANC / (WBC + epsilon)\n",
    "    MONOCYTES_WBC = MONOCYTES / (WBC + epsilon)\n",
    "    PLT_WBC = np.log1p(PLT / (WBC +epsilon)) # We use log1p because data or often asymetric\n",
    "    HB_WBC = HB / (WBC + epsilon)\n",
    "\n",
    "    BURDEN = WBC * (BM_BLAST/100)\n",
    "\n",
    "    BLAST_20 = (BM_BLAST >= 20).astype(int).mask(BM_BLAST.isna())\n",
    "    WBC_100 = (WBC >= 100).astype(int).mask(WBC.isna())\n",
    "\n",
    "    return pd.DataFrame({\n",
    "        \"WBC_LOG\": np.log1p(WBC),\n",
    "        \"ANC_WBC\": ANC_WBC,\n",
    "        \"MONOCYTES_WBC\": MONOCYTES_WBC,\n",
    "        \"PLT_WBC\": PLT_WBC, \n",
    "        \"HB_WBC\": HB_WBC,\n",
    "        \"BURDEN\": BURDEN,\n",
    "        \"BLAST_20\": BLAST_20,\n",
    "        \"WBC_100\": WBC_100\n",
    "    })\n",
    "\n",
    "df_clinical_ratio_train = clinical_ratio(df_clinical_train)\n",
    "df_clinical_train = pd.concat([df_clinical_train, df_clinical_ratio_train], axis=1)\n",
    "df_clinical_ratio_test = clinical_ratio(df_clinical_test)\n",
    "df_clinical_test = pd.concat([df_clinical_test, df_clinical_ratio_test], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2095814b",
   "metadata": {},
   "source": [
    "We extract fundamental biological features by parsing the karyotype string to retrieve the number of chromosomes and encode the biological sex (XX vs XY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2f75ae94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_sex_chromosome(cytogenetics):\n",
    "\n",
    "    if pd.isna(cytogenetics):\n",
    "        return None, None\n",
    "    \n",
    "    clone = cytogenetics.split(',')\n",
    "\n",
    "    chromosomes = clone[0]\n",
    "    try:\n",
    "        chromosomes = int(chromosomes)\n",
    "    except:\n",
    "        chromosomes = None\n",
    "    \n",
    "    sex = None\n",
    "    if len(clone)>1:\n",
    "        match = re.search(r'(XX|XY)', clone[1], re.IGNORECASE)\n",
    "        if match:\n",
    "            sex = match.group(1).upper()\n",
    "            if sex == 'XX':\n",
    "                sex = 2\n",
    "            elif sex == 'XY':\n",
    "                sex = 1\n",
    "            else:\n",
    "                sex = 0\n",
    "        \n",
    "    return chromosomes, sex\n",
    "\n",
    "df_clinical_train[['CHROMOSOMES', 'SEX']] = df_clinical_train['CYTOGENETICS'].apply(lambda x: pd.Series(extract_sex_chromosome(x))).replace({None: np.nan})\n",
    "df_clinical_test[['CHROMOSOMES', 'SEX']] = df_clinical_test['CYTOGENETICS'].apply(lambda x: pd.Series(extract_sex_chromosome(x))).replace({None: np.nan})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3968b0b",
   "metadata": {},
   "source": [
    "We use regular expressions to parse the cytogenetic string and extract binary features for specific chromosomal abnormalities associated with favorable or adverse diagnosis (e.g., t(8;21), monosomy 7, complex karyotype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5023b966",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_specific_cytogenetics(cyto):\n",
    "\n",
    "    if pd.isna(cyto):\n",
    "         return pd.Series([0, 0, 0, 0, 0, 0, 0],\n",
    "                            index=[\"CYTO_t8_21\", \"CYTO_inv16\", \"CYTO_t15_17\", \"CYTO_mono_5_7\", \n",
    "                                   \"CYTO_del_5q_7q\", \"CYTO_inv3\", \"CYTO_is_complex\"])\n",
    "    \n",
    "    cytogenetic = str(cyto).lower()\n",
    "\n",
    "    # t(8;21)\n",
    "    t8_21 = 1 if re.search(r't\\(8;21\\)', cytogenetic) else 0\n",
    "    # Inversion on 16\n",
    "    inv16 = 1 if re.search(r'inv\\(16\\)|t\\(16;16\\)', cytogenetic) else 0\n",
    "    # Leucimia promyélocytraire\n",
    "    t15_17 = 1 if re.search(r't\\(15;17\\)', cytogenetic) else 0\n",
    "\n",
    "    # Monosomi 5 or 7\n",
    "    mono_5_7 = 1 if re.search(r'(^|[,\\s])(-5|-7)([,\\s]|$)', cytogenetic) else 0\n",
    "    # del 5q or 7q\n",
    "    del_5q_7q = 1 if re.search(r'del\\((5|5q|7|7q)\\)', cytogenetic) else 0\n",
    "    # Inversion on 3\n",
    "    inv3 = 1 if re.search(r'inv\\(3\\)|t\\(3;3\\)', cytogenetic) else 0\n",
    "\n",
    "    is_complex = 1 if 'complex' in cytogenetic or cytogenetic.count(',') > 5 else 0 \n",
    "\n",
    "    return pd.Series([t8_21, inv16, t15_17, mono_5_7, del_5q_7q, inv3, is_complex],\n",
    "                     index=[\"CYTO_t8_21\", \"CYTO_inv16\", \"CYTO_t15_17\", \"CYTO_mono_5_7\", \"CYTO_del_5q_7q\", \"CYTO_inv3\", \"CYTO_is_complex\"])\n",
    "\n",
    "cyto_feature_train = df_clinical_train['CYTOGENETICS'].apply(extract_specific_cytogenetics)\n",
    "df_clinical_train = pd.concat([df_clinical_train, cyto_feature_train], axis=1)\n",
    "\n",
    "cyto_feature_test = df_clinical_test['CYTOGENETICS'].apply(extract_specific_cytogenetics)\n",
    "df_clinical_test = pd.concat([df_clinical_test, cyto_feature_test], axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6a5f730",
   "metadata": {},
   "source": [
    "We parse the cytogenetics string to count the number of clones and specific types of mutations (deletions, duplications, translocations) for each patient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b7262346",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clinical_train['NUM_CLONE'] = df_clinical_train['CYTOGENETICS'].str.count(r'/') #Count the number of clone in the cytogenetics\n",
    "df_clinical_test['NUM_CLONE'] = df_clinical_test['CYTOGENETICS'].str.count(r'/')\n",
    "\n",
    "df_clinical_train['NUM_DELETION'] = df_clinical_train['CYTOGENETICS'].str.count(r'del\\(')\n",
    "df_clinical_test['NUM_DELETION'] = df_clinical_test['CYTOGENETICS'].str.count(r'del\\(')\n",
    "\n",
    "df_clinical_train['NUM_DUPLICATION'] = df_clinical_train['CYTOGENETICS'].str.count(r'dup\\(')\n",
    "df_clinical_test['NUM_DUPLICATION'] = df_clinical_test['CYTOGENETICS'].str.count(r'dup\\(')\n",
    "\n",
    "df_clinical_train['NUM_ISOCHROMOSOME'] = df_clinical_train['CYTOGENETICS'].str.count(r'i\\(')\n",
    "df_clinical_test['NUM_ISOCHROMOSOME'] = df_clinical_test['CYTOGENETICS'].str.count(r'i\\(')\n",
    "\n",
    "df_clinical_train['NUM_TRANSLOCATION'] = df_clinical_train['CYTOGENETICS'].str.count(r't\\(')\n",
    "df_clinical_test['NUM_TRANSLOCATION'] = df_clinical_test['CYTOGENETICS'].str.count(r't\\(')\n",
    "\n",
    "df_clinical_train['NUM_INSERTION'] = df_clinical_train['CYTOGENETICS'].str.count(r'ins\\(')\n",
    "df_clinical_test['NUM_INSERTION'] = df_clinical_test['CYTOGENETICS'].str.count(r'ins\\(')\n",
    "\n",
    "df_clinical_train['NUM_INVERSION'] = df_clinical_train['CYTOGENETICS'].str.count(r'inv\\(')\n",
    "df_clinical_test['NUM_INVERSION'] = df_clinical_test['CYTOGENETICS'].str.count(r'inv\\(')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fcb9435",
   "metadata": {},
   "source": [
    "We parse the text to identify and count all unique chromosomes that present an anomaly (deletion, addition, or structural change)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "26225793",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unique_chromosome(cyto):\n",
    "    if pd.isna(cyto):\n",
    "        return 0\n",
    "    chromosome_in_paranthese = re.findall(r'\\((\\d{1,2})[p,q]?', cyto)\n",
    "    chromosome_numeric = re.findall(r'[+-](\\d{1,2})', cyto)\n",
    "    all_chrom = list(map(int,chromosome_in_paranthese + chromosome_numeric))\n",
    "\n",
    "    return len(set(all_chrom))\n",
    "\n",
    "df_clinical_train['NUM_UNIQUE_CHROM'] = df_clinical_train['CYTOGENETICS'].apply(unique_chromosome)\n",
    "df_clinical_test['NUM_UNIQUE_CHROM'] = df_clinical_test['CYTOGENETICS'].apply(unique_chromosome)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ab2fa373",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----CLINICAL TRAIN DATA----\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>CENTER</th>\n",
       "      <th>BM_BLAST</th>\n",
       "      <th>WBC</th>\n",
       "      <th>ANC</th>\n",
       "      <th>MONOCYTES</th>\n",
       "      <th>HB</th>\n",
       "      <th>PLT</th>\n",
       "      <th>CYTOGENETICS</th>\n",
       "      <th>WBC_LOG</th>\n",
       "      <th>...</th>\n",
       "      <th>CYTO_inv3</th>\n",
       "      <th>CYTO_is_complex</th>\n",
       "      <th>NUM_CLONE</th>\n",
       "      <th>NUM_DELETION</th>\n",
       "      <th>NUM_DUPLICATION</th>\n",
       "      <th>NUM_ISOCHROMOSOME</th>\n",
       "      <th>NUM_TRANSLOCATION</th>\n",
       "      <th>NUM_INSERTION</th>\n",
       "      <th>NUM_INVERSION</th>\n",
       "      <th>NUM_UNIQUE_CHROM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P132697</td>\n",
       "      <td>MSK</td>\n",
       "      <td>14.0</td>\n",
       "      <td>2.8</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.7</td>\n",
       "      <td>7.6</td>\n",
       "      <td>119.0</td>\n",
       "      <td>46,xy,del(20)(q12)[2]/46,xy[18]</td>\n",
       "      <td>1.335001</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>P132698</td>\n",
       "      <td>MSK</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.4</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0.1</td>\n",
       "      <td>11.6</td>\n",
       "      <td>42.0</td>\n",
       "      <td>46,xx</td>\n",
       "      <td>2.128232</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>P116889</td>\n",
       "      <td>MSK</td>\n",
       "      <td>15.0</td>\n",
       "      <td>3.7</td>\n",
       "      <td>2.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>14.2</td>\n",
       "      <td>81.0</td>\n",
       "      <td>46,xy,t(3;3)(q25;q27)[8]/46,xy[12]</td>\n",
       "      <td>1.547563</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>P132699</td>\n",
       "      <td>MSK</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.1</td>\n",
       "      <td>8.9</td>\n",
       "      <td>77.0</td>\n",
       "      <td>46,xy,del(3)(q26q27)[15]/46,xy[5]</td>\n",
       "      <td>1.589235</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>P132700</td>\n",
       "      <td>MSK</td>\n",
       "      <td>6.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>9.7</td>\n",
       "      <td>0.9</td>\n",
       "      <td>11.1</td>\n",
       "      <td>195.0</td>\n",
       "      <td>46,xx,t(3;9)(p13;q22)[10]/46,xx[10]</td>\n",
       "      <td>4.859812</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ID CENTER  BM_BLAST    WBC  ANC  MONOCYTES    HB    PLT  \\\n",
       "0  P132697    MSK      14.0    2.8  0.2        0.7   7.6  119.0   \n",
       "1  P132698    MSK       1.0    7.4  2.4        0.1  11.6   42.0   \n",
       "2  P116889    MSK      15.0    3.7  2.1        0.1  14.2   81.0   \n",
       "3  P132699    MSK       1.0    3.9  1.9        0.1   8.9   77.0   \n",
       "4  P132700    MSK       6.0  128.0  9.7        0.9  11.1  195.0   \n",
       "\n",
       "                          CYTOGENETICS   WBC_LOG  ...  CYTO_inv3  \\\n",
       "0      46,xy,del(20)(q12)[2]/46,xy[18]  1.335001  ...          0   \n",
       "1                                46,xx  2.128232  ...          0   \n",
       "2   46,xy,t(3;3)(q25;q27)[8]/46,xy[12]  1.547563  ...          1   \n",
       "3    46,xy,del(3)(q26q27)[15]/46,xy[5]  1.589235  ...          0   \n",
       "4  46,xx,t(3;9)(p13;q22)[10]/46,xx[10]  4.859812  ...          0   \n",
       "\n",
       "   CYTO_is_complex  NUM_CLONE  NUM_DELETION  NUM_DUPLICATION  \\\n",
       "0                0        1.0           1.0              0.0   \n",
       "1                0        0.0           0.0              0.0   \n",
       "2                0        1.0           0.0              0.0   \n",
       "3                0        1.0           1.0              0.0   \n",
       "4                0        1.0           0.0              0.0   \n",
       "\n",
       "   NUM_ISOCHROMOSOME  NUM_TRANSLOCATION  NUM_INSERTION  NUM_INVERSION  \\\n",
       "0                0.0                0.0            0.0            0.0   \n",
       "1                0.0                0.0            0.0            0.0   \n",
       "2                0.0                1.0            0.0            0.0   \n",
       "3                0.0                0.0            0.0            0.0   \n",
       "4                0.0                1.0            0.0            0.0   \n",
       "\n",
       "   NUM_UNIQUE_CHROM  \n",
       "0                 1  \n",
       "1                 0  \n",
       "2                 1  \n",
       "3                 1  \n",
       "4                 1  \n",
       "\n",
       "[5 rows x 34 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----CLINICAL TEST DATA----\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>CENTER</th>\n",
       "      <th>BM_BLAST</th>\n",
       "      <th>WBC</th>\n",
       "      <th>ANC</th>\n",
       "      <th>MONOCYTES</th>\n",
       "      <th>HB</th>\n",
       "      <th>PLT</th>\n",
       "      <th>CYTOGENETICS</th>\n",
       "      <th>WBC_LOG</th>\n",
       "      <th>...</th>\n",
       "      <th>CYTO_inv3</th>\n",
       "      <th>CYTO_is_complex</th>\n",
       "      <th>NUM_CLONE</th>\n",
       "      <th>NUM_DELETION</th>\n",
       "      <th>NUM_DUPLICATION</th>\n",
       "      <th>NUM_ISOCHROMOSOME</th>\n",
       "      <th>NUM_TRANSLOCATION</th>\n",
       "      <th>NUM_INSERTION</th>\n",
       "      <th>NUM_INVERSION</th>\n",
       "      <th>NUM_UNIQUE_CHROM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KYW1</td>\n",
       "      <td>KYW</td>\n",
       "      <td>68.0</td>\n",
       "      <td>3.45</td>\n",
       "      <td>0.5865</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.6</td>\n",
       "      <td>48.0</td>\n",
       "      <td>47,XY,+X,del(9)(q?)[15]/47,XY,+X[5]</td>\n",
       "      <td>1.492904</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KYW2</td>\n",
       "      <td>KYW</td>\n",
       "      <td>35.0</td>\n",
       "      <td>3.18</td>\n",
       "      <td>1.2402</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>46,XY,der(3)?t(3;11)(q26.2;q23),add(4)(p15).de...</td>\n",
       "      <td>1.430311</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KYW3</td>\n",
       "      <td>KYW</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.40</td>\n",
       "      <td>8.6800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.3</td>\n",
       "      <td>25.0</td>\n",
       "      <td>47,XX,+8</td>\n",
       "      <td>2.595255</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>KYW4</td>\n",
       "      <td>KYW</td>\n",
       "      <td>61.0</td>\n",
       "      <td>5.55</td>\n",
       "      <td>2.0535</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>1.879465</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>KYW5</td>\n",
       "      <td>KYW</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.21</td>\n",
       "      <td>0.7381</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.6</td>\n",
       "      <td>27.0</td>\n",
       "      <td>43,XY,dic(5;17)(q11.2;p11.2),-7,-13,-20,-22,+r...</td>\n",
       "      <td>0.792993</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     ID CENTER  BM_BLAST    WBC     ANC  MONOCYTES    HB   PLT  \\\n",
       "0  KYW1    KYW      68.0   3.45  0.5865        NaN   7.6  48.0   \n",
       "1  KYW2    KYW      35.0   3.18  1.2402        NaN  10.0  32.0   \n",
       "2  KYW3    KYW       NaN  12.40  8.6800        NaN  12.3  25.0   \n",
       "3  KYW4    KYW      61.0   5.55  2.0535        NaN   8.0  44.0   \n",
       "4  KYW5    KYW       2.0   1.21  0.7381        NaN   8.6  27.0   \n",
       "\n",
       "                                        CYTOGENETICS   WBC_LOG  ...  \\\n",
       "0                47,XY,+X,del(9)(q?)[15]/47,XY,+X[5]  1.492904  ...   \n",
       "1  46,XY,der(3)?t(3;11)(q26.2;q23),add(4)(p15).de...  1.430311  ...   \n",
       "2                                           47,XX,+8  2.595255  ...   \n",
       "3                                             Normal  1.879465  ...   \n",
       "4  43,XY,dic(5;17)(q11.2;p11.2),-7,-13,-20,-22,+r...  0.792993  ...   \n",
       "\n",
       "   CYTO_inv3  CYTO_is_complex  NUM_CLONE  NUM_DELETION  NUM_DUPLICATION  \\\n",
       "0          0                0        1.0           1.0              0.0   \n",
       "1          0                0        0.0           1.0              0.0   \n",
       "2          0                0        0.0           0.0              0.0   \n",
       "3          0                0        0.0           0.0              0.0   \n",
       "4          0                1        2.0           0.0              0.0   \n",
       "\n",
       "   NUM_ISOCHROMOSOME  NUM_TRANSLOCATION  NUM_INSERTION  NUM_INVERSION  \\\n",
       "0                0.0                0.0            0.0            0.0   \n",
       "1                0.0                2.0            0.0            0.0   \n",
       "2                0.0                0.0            0.0            0.0   \n",
       "3                0.0                0.0            0.0            0.0   \n",
       "4                0.0                0.0            0.0            0.0   \n",
       "\n",
       "   NUM_UNIQUE_CHROM  \n",
       "0                 1  \n",
       "1                 3  \n",
       "2                 1  \n",
       "3                 0  \n",
       "4                 5  \n",
       "\n",
       "[5 rows x 34 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"----CLINICAL TRAIN DATA----\")\n",
    "display(df_clinical_train.head())\n",
    "\n",
    "print(\"----CLINICAL TEST DATA----\")\n",
    "display(df_clinical_test.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1393ee5",
   "metadata": {},
   "source": [
    "## B. Molecular data engineering "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2b43561",
   "metadata": {},
   "source": [
    "We group the molecular data by patient ID to calculate the total count of mutations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "885ac7f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We count the number of mutation\n",
    "nmut_df_train = df_molecular_train.groupby('ID').size().reset_index()\n",
    "nmut_df_train.columns = ['ID', 'NMUT']\n",
    "\n",
    "nmut_df_test = df_molecular_test.groupby('ID').size().reset_index()\n",
    "nmut_df_test.columns = ['ID', 'NMUT']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68d6a228",
   "metadata": {},
   "source": [
    "We aggregate the molecular data to count how many distinct genes carry mutations for each patient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d5f53563",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We also add a feature that will count the number of unique genes affected for each patient\n",
    "df_uniquegene_train = df_molecular_train.groupby('ID')['GENE'].nunique().reset_index(name='UNIQUE_GENES')\n",
    "df_uniquegene_test = df_molecular_test.groupby('ID')['GENE'].nunique().reset_index(name='UNIQUE_GENES')\n",
    "\n",
    "df_molecular_train_modified = nmut_df_train.merge(df_uniquegene_train, on='ID', how='left').fillna({'UNIQUE_GENES':np.nan})\n",
    "df_molecular_test_modified = nmut_df_test.merge(df_uniquegene_test, on='ID', how='left').fillna({'UNIQUE_GENES':np.nan})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76d06c9f",
   "metadata": {},
   "source": [
    "We classify mutations into favorable or unfavorable categories and sum their contributions to create a global genetic risk score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1e6a3b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gene_classifier(gene_row):\n",
    "    favorable_gene = ['NPM1', 'CEBPA', 'DDX41', 'SF3B1', 'ETV6', 'IDH1', 'IDH2']\n",
    "    defavorable_gene = ['TP53', 'FLT3','ASXL1', 'RUNX1', 'WT1', 'NRAS', 'KRAS', 'KIT', 'PHF6', \n",
    "                        'SETBP1', 'PTEN', 'RB1', 'ATRX', 'BRAF', 'MYC', 'MLL', 'CDKN2A', 'CDK4', 'ABL1']\n",
    "\n",
    "    if not isinstance(gene_row, str):\n",
    "        return None\n",
    "\n",
    "    if any(gene in gene_row for gene in favorable_gene):\n",
    "        return -1\n",
    "    if any(gene in gene_row for gene in defavorable_gene):\n",
    "        return 1\n",
    "\n",
    "    return 0\n",
    "\n",
    "# Train\n",
    "df_molecular_train['GENE_SCORE'] = df_molecular_train['GENE'].apply(lambda x: gene_classifier(x)).replace({None: np.nan})\n",
    "df_gene_score_train = df_molecular_train.groupby('ID')['GENE_SCORE'].sum().reset_index()\n",
    "df_molecular_train_modified = df_molecular_train_modified.merge(df_gene_score_train, on='ID', how='left').fillna({'GENE_SCORE':np.nan})\n",
    "\n",
    "\n",
    "# Test\n",
    "df_molecular_test['GENE_SCORE'] = df_molecular_test['GENE'].apply(lambda x: gene_classifier(x)).replace({None: np.nan})\n",
    "df_gene_score_test = df_molecular_test.groupby('ID')['GENE_SCORE'].sum().reset_index()\n",
    "df_molecular_test_modified = df_molecular_test_modified.merge(df_gene_score_test, on='ID', how='left').fillna({'GENE_SCORE':np.nan})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebe3aa83",
   "metadata": {},
   "source": [
    "We apply one-hot encoding to the most frequent genes (minimum frequency of 15) to create a binary matrix representing the presence or absence of key driver mutations for each patient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2bda2e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_gene(data_df, min_frequency=15):\n",
    "    gene_counts = data_df['GENE'].value_counts()\n",
    "    top_genes = gene_counts[gene_counts >= min_frequency].index.tolist()\n",
    "    return top_genes\n",
    "\n",
    "top_genes = get_top_gene(df_molecular_train)\n",
    "\n",
    "def create_gene_feature(molecular_df, selected_gene):\n",
    "    subset_df = molecular_df[molecular_df['GENE'].isin(selected_gene)]\n",
    "\n",
    "    # We pivot data : \n",
    "    # Index = ID of the patient\n",
    "    # Column = Gene\n",
    "    # Value = 1 if present (count), 0 if not\n",
    "    gene_matrix = pd.crosstab(subset_df['ID'], subset_df['GENE'])\n",
    "\n",
    "    # We only wont binary data\n",
    "    gene_matrix = (gene_matrix > 0).astype(int)\n",
    "\n",
    "    # If one of the top gene are not is the data, we add the column with only 0\n",
    "    gene_matrix = gene_matrix.reindex(columns=selected_gene, fill_value=0)\n",
    "\n",
    "    gene_matrix.columns = [f'GENE_{g}' for g in gene_matrix.columns]\n",
    "\n",
    "    return gene_matrix\n",
    "\n",
    "df_gene_feature_train = create_gene_feature(df_molecular_train, top_genes)\n",
    "df_gene_feature_test = create_gene_feature(df_molecular_test, top_genes)\n",
    "\n",
    "df_molecular_train_modified = df_molecular_train_modified.merge(df_gene_feature_train, on='ID', how='left')\n",
    "df_molecular_test_modified = df_molecular_test_modified.merge(df_gene_feature_test, on='ID', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be99220e",
   "metadata": {},
   "source": [
    "We isolate the VAF values for specific dangerous genes to provide the model with information about the intensity of these mutations (we only use the 3 most dangerous gene)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "509418e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We compute the VAF mean for each gene that are classified as risky \n",
    "defavorable_gene = ['TP53', 'FLT3', 'RUNX1']\n",
    "\n",
    "df_vaf_gene_specific_train = pd.DataFrame(df_molecular_train['ID'].unique(), columns=['ID'])\n",
    "df_vaf_gene_specific_test = pd.DataFrame(df_molecular_test['ID'].unique(), columns=['ID'])\n",
    "\n",
    "for gene in defavorable_gene:\n",
    "    vaf_gene_train_temp = df_molecular_train[df_molecular_train['GENE'] == gene].groupby('ID')['VAF'].mean().reset_index(name=f'VAF_{gene}')\n",
    "    df_vaf_gene_specific_train = df_vaf_gene_specific_train.merge(vaf_gene_train_temp, on='ID', how='left').fillna({f'VAF_{gene}':0})\n",
    "\n",
    "    vaf_gene_test_temp = df_molecular_test[df_molecular_test['GENE'] == gene].groupby('ID')['VAF'].mean().reset_index(name=f'VAF_{gene}')\n",
    "    df_vaf_gene_specific_test = df_vaf_gene_specific_test.merge(vaf_gene_test_temp, on='ID', how='left').fillna({f'VAF_{gene}':0})\n",
    "\n",
    "df_molecular_train_modified = df_molecular_train_modified.merge(df_vaf_gene_specific_train, on='ID', how='left')\n",
    "df_molecular_test_modified = df_molecular_test_modified.merge(df_vaf_gene_specific_test, on='ID', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67ee1500",
   "metadata": {},
   "source": [
    "We aggregate the VAF data to extract the mean, maximum, and total sum of variant frequencies for each patient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "dd9d7f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vaf_stats_train = df_molecular_train.groupby('ID')['VAF'].agg(['mean', 'max', 'sum']).reset_index()\n",
    "df_vaf_stats_train.columns = ['ID', 'MEAN_VAF', 'MAX_VAF', 'SUM_VAF']\n",
    "\n",
    "df_vaf_stats_test = df_molecular_test.groupby('ID')['VAF'].agg(['mean', 'max', 'sum']).reset_index()\n",
    "df_vaf_stats_test.columns = ['ID', 'MEAN_VAF', 'MAX_VAF', 'SUM_VAF']\n",
    "\n",
    "df_molecular_train_modified = df_molecular_train_modified.merge(df_vaf_stats_train, on='ID', how='left').fillna({'MEAN_VAF':np.nan, 'MAX_VAF':np.nan, 'SUM_VAF':np.nan})\n",
    "df_molecular_test_modified = df_molecular_test_modified.merge(df_vaf_stats_test, on='ID', how='left').fillna({'MEAN_VAF':np.nan, 'MAX_VAF':np.nan, 'SUM_VAF':np.nan})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "421b00cf",
   "metadata": {},
   "source": [
    "We compute the ratios of different mutation effects (such as frameshift or stop-gained variants) relative to the total count of mutations to assess the severity of genetic alterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "48e50042",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ratio_frameshift_variant(effect_data):\n",
    "    num_mutation = effect_data.shape[0]\n",
    "    if num_mutation == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        num_framsehift_variant = (effect_data == 'frameshift_variant').sum()\n",
    "        ratio = num_framsehift_variant / num_mutation\n",
    "        return ratio\n",
    "\n",
    "def ratio_stop_gained(effect_data):\n",
    "    num_mutation = effect_data.shape[0]\n",
    "    if num_mutation == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        num_stop_gained = (effect_data == 'stop_gained').sum()\n",
    "        ratio = num_stop_gained / num_mutation\n",
    "        return ratio\n",
    "\n",
    "def ratio_stop_lost(effect_data):\n",
    "    num_mutation = effect_data.shape[0]\n",
    "    if num_mutation == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        num_stop_lost = (effect_data == 'stop_lost').sum()\n",
    "        ratio = num_stop_lost / num_mutation\n",
    "        return ratio\n",
    "\n",
    "def ratio_splice_site_variant(effect_data):\n",
    "    num_mutation = effect_data.shape[0]\n",
    "    if num_mutation == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        num_ss_variant = (effect_data == 'splice_site_variant').sum()\n",
    "        ratio = num_ss_variant / num_mutation\n",
    "        return ratio\n",
    "\n",
    "df_frameshit_variant_effect_train = df_molecular_train.groupby('ID')['EFFECT'].apply(ratio_frameshift_variant).reset_index(name='RATIO_FRAMESHIFT_VARIANT')\n",
    "df_frameshit_variant_effect_test = df_molecular_test.groupby('ID')['EFFECT'].apply(ratio_frameshift_variant).reset_index(name='RATIO_FRAMESHIFT_VARIANT')\n",
    "\n",
    "df_stop_gained_effect_train = df_molecular_train.groupby('ID')['EFFECT'].apply(ratio_stop_gained).reset_index(name='RATIO_STOP_GAINED')\n",
    "df_stop_gained_effect_test = df_molecular_test.groupby('ID')['EFFECT'].apply(ratio_stop_gained).reset_index(name='RATIO_STOP_GAINED')\n",
    "\n",
    "df_stop_lost_effect_train = df_molecular_train.groupby('ID')['EFFECT'].apply(ratio_stop_lost).reset_index(name='RATIO_STOP_LOST')\n",
    "df_stop_lost_effect_test = df_molecular_test.groupby('ID')['EFFECT'].apply(ratio_stop_lost).reset_index(name='RATIO_STOP_LOST')\n",
    "\n",
    "df_splice_site_variant_effect_train = df_molecular_train.groupby('ID')['EFFECT'].apply(ratio_splice_site_variant).reset_index(name='RATIO_SPLICE_SITE_VARIANT')\n",
    "df_splice_site_variant_effect_test = df_molecular_test.groupby('ID')['EFFECT'].apply(ratio_splice_site_variant).reset_index(name='RATIO_SPLICE_SITE_VARIANT')\n",
    "\n",
    "df_effect_train = (\n",
    "    df_frameshit_variant_effect_train\n",
    "    .merge(df_stop_gained_effect_train, on='ID', how='left')\n",
    "    .merge(df_stop_lost_effect_train, on='ID', how='left')\n",
    "    .merge(df_splice_site_variant_effect_train, on='ID', how='left')\n",
    ")\n",
    "\n",
    "df_effect_test = (\n",
    "    df_frameshit_variant_effect_test\n",
    "    .merge(df_stop_gained_effect_test, on='ID', how='left')\n",
    "    .merge(df_stop_lost_effect_test, on='ID', how='left')\n",
    "    .merge(df_splice_site_variant_effect_test, on='ID', how='left')\n",
    ")\n",
    "\n",
    "\n",
    "df_molecular_train_modified = df_molecular_train_modified.merge(df_effect_train, on='ID', how='left')\n",
    "df_molecular_test_modified = df_molecular_test_modified.merge(df_effect_test, on='ID', how='left')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5743b6c3",
   "metadata": {},
   "source": [
    "We map categorical mutation effects to a numerical severity scale (0 for neutral, 2 for very bad) and calculate summary statistics to represent the overall biological damage for each patient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "706171a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "effect_score = {\n",
    "    # Very Bad\n",
    "    'frameshift_variant': 2,\n",
    "    'stop_gained': 2,\n",
    "    'stop_lost': 2,\n",
    "    'splice_site_variant': 2,\n",
    "    'PTD': 2,\n",
    "    'ITD': 2,\n",
    "\n",
    "    # Bad\n",
    "    'non_synonymous_codon': 1,\n",
    "    'inframe_codon_loss': 1,\n",
    "    'inframe_codon_gain': 1,\n",
    "    'inframe_variant': 1,\n",
    "    'initiator_codon_change': 1,\n",
    "    'complex_change_in_transcript': 1,\n",
    "\n",
    "    # Neutral\n",
    "    'synonymous_codon': 0,\n",
    "    'stop_retained_variant': 0,\n",
    "    '3_prime_UTR_variant': 0,\n",
    "    '2KB_upstream_variant': 0\n",
    "}\n",
    "\n",
    "df_molecular_train['EFFECT_SCORE'] = df_molecular_train['EFFECT'].map(effect_score).fillna(0)\n",
    "effect_score_df_train = df_molecular_train.groupby('ID')['EFFECT_SCORE'].agg(['mean', 'max', 'sum']).reset_index()\n",
    "effect_score_df_train.columns = ['ID', 'MEAN_EFFECT', 'MAX_EFFECT', 'SUM_EFFECT']\n",
    "\n",
    "df_molecular_test['EFFECT_SCORE'] = df_molecular_test['EFFECT'].map(effect_score).fillna(0)\n",
    "effect_score_df_test = df_molecular_test.groupby('ID')['EFFECT_SCORE'].agg(['mean', 'max', 'sum']).reset_index()\n",
    "effect_score_df_test.columns = ['ID', 'MEAN_EFFECT', 'MAX_EFFECT', 'SUM_EFFECT']\n",
    "\n",
    "df_molecular_train_modified = (\n",
    "    df_molecular_train_modified\n",
    "    .merge(effect_score_df_train, on='ID', how='left').fillna({'MEAN_EFFECT':np.nan, 'MAX_EFFECT':np.nan, 'SUM_EFFECT':np.nan})\n",
    ")\n",
    "\n",
    "df_molecular_test_modified = (\n",
    "    df_molecular_test_modified\n",
    "    .merge(effect_score_df_test, on='ID', how='left').fillna({'MEAN_EFFECT':np.nan, 'MAX_EFFECT':np.nan, 'SUM_EFFECT':np.nan})\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8421937f",
   "metadata": {},
   "source": [
    "We identify common mutation effects and create binary features to flag their presence for each patient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c0552e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_common_effect(data_df, min_frequency=10):\n",
    "    effect_counts = data_df['EFFECT'].value_counts()\n",
    "    common_effect = effect_counts[effect_counts >= min_frequency].index.tolist()\n",
    "    return common_effect\n",
    "\n",
    "def create_binary_effect_features(data_df, common_effect):\n",
    "\n",
    "    all_ids = data_df['ID'].unique()\n",
    "    df_effect_features = pd.DataFrame({'ID': all_ids})\n",
    "\n",
    "    for effect in common_effect:\n",
    "        feature_name = f'HAS_{effect.upper()}'\n",
    "        ids_with_effect = data_df[data_df['EFFECT'] == effect]['ID'].unique()\n",
    "        df_effect_features[feature_name] = df_effect_features['ID'].isin(ids_with_effect).astype(int)\n",
    "    return df_effect_features\n",
    "\n",
    "critical_effect = get_common_effect(df_molecular_train)\n",
    "df_binary_effect_features_train = create_binary_effect_features(df_molecular_train, critical_effect)\n",
    "df_binary_effect_features_test = create_binary_effect_features(df_molecular_test, critical_effect)\n",
    "\n",
    "df_molecular_train_modified = df_molecular_train_modified.merge(df_binary_effect_features_train, on='ID', how='left')\n",
    "df_molecular_test_modified = df_molecular_test_modified.merge(df_binary_effect_features_test, on='ID', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "275555c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----MOLECULAR TRAIN DATA----\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>NMUT</th>\n",
       "      <th>UNIQUE_GENES</th>\n",
       "      <th>GENE_SCORE</th>\n",
       "      <th>GENE_TET2</th>\n",
       "      <th>GENE_ASXL1</th>\n",
       "      <th>GENE_SF3B1</th>\n",
       "      <th>GENE_DNMT3A</th>\n",
       "      <th>GENE_RUNX1</th>\n",
       "      <th>GENE_SRSF2</th>\n",
       "      <th>...</th>\n",
       "      <th>HAS_FRAMESHIFT_VARIANT</th>\n",
       "      <th>HAS_STOP_GAINED</th>\n",
       "      <th>HAS_SPLICE_SITE_VARIANT</th>\n",
       "      <th>HAS_INFRAME_CODON_LOSS</th>\n",
       "      <th>HAS_PTD</th>\n",
       "      <th>HAS_INFRAME_CODON_GAIN</th>\n",
       "      <th>HAS_ITD</th>\n",
       "      <th>HAS_INITIATOR_CODON_CHANGE</th>\n",
       "      <th>HAS_2KB_UPSTREAM_VARIANT</th>\n",
       "      <th>HAS_COMPLEX_CHANGE_IN_TRANSCRIPT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P100000</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>P100001</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>P100002</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>P100004</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>P100006</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 98 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ID  NMUT  UNIQUE_GENES  GENE_SCORE  GENE_TET2  GENE_ASXL1  GENE_SF3B1  \\\n",
       "0  P100000     6             6           0        1.0         0.0         0.0   \n",
       "1  P100001     2             2           0        NaN         NaN         NaN   \n",
       "2  P100002     2             2           1        0.0         0.0         0.0   \n",
       "3  P100004     1             1           0        0.0         0.0         0.0   \n",
       "4  P100006     5             5           0        1.0         0.0         0.0   \n",
       "\n",
       "   GENE_DNMT3A  GENE_RUNX1  GENE_SRSF2  ...  HAS_FRAMESHIFT_VARIANT  \\\n",
       "0          1.0         0.0         0.0  ...                       1   \n",
       "1          NaN         NaN         NaN  ...                       0   \n",
       "2          0.0         0.0         0.0  ...                       0   \n",
       "3          0.0         0.0         0.0  ...                       1   \n",
       "4          0.0         0.0         1.0  ...                       1   \n",
       "\n",
       "   HAS_STOP_GAINED  HAS_SPLICE_SITE_VARIANT  HAS_INFRAME_CODON_LOSS  HAS_PTD  \\\n",
       "0                1                        1                       0        0   \n",
       "1                1                        0                       0        0   \n",
       "2                1                        0                       0        0   \n",
       "3                0                        0                       0        0   \n",
       "4                1                        0                       0        0   \n",
       "\n",
       "   HAS_INFRAME_CODON_GAIN  HAS_ITD  HAS_INITIATOR_CODON_CHANGE  \\\n",
       "0                       0        0                           0   \n",
       "1                       0        0                           0   \n",
       "2                       0        0                           0   \n",
       "3                       0        0                           0   \n",
       "4                       0        0                           0   \n",
       "\n",
       "   HAS_2KB_UPSTREAM_VARIANT  HAS_COMPLEX_CHANGE_IN_TRANSCRIPT  \n",
       "0                         0                                 0  \n",
       "1                         0                                 0  \n",
       "2                         0                                 0  \n",
       "3                         0                                 0  \n",
       "4                         0                                 0  \n",
       "\n",
       "[5 rows x 98 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----MOLECULAR TEST DATA----\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>NMUT</th>\n",
       "      <th>UNIQUE_GENES</th>\n",
       "      <th>GENE_SCORE</th>\n",
       "      <th>GENE_TET2</th>\n",
       "      <th>GENE_ASXL1</th>\n",
       "      <th>GENE_SF3B1</th>\n",
       "      <th>GENE_DNMT3A</th>\n",
       "      <th>GENE_RUNX1</th>\n",
       "      <th>GENE_SRSF2</th>\n",
       "      <th>...</th>\n",
       "      <th>HAS_FRAMESHIFT_VARIANT</th>\n",
       "      <th>HAS_STOP_GAINED</th>\n",
       "      <th>HAS_SPLICE_SITE_VARIANT</th>\n",
       "      <th>HAS_INFRAME_CODON_LOSS</th>\n",
       "      <th>HAS_PTD</th>\n",
       "      <th>HAS_INFRAME_CODON_GAIN</th>\n",
       "      <th>HAS_ITD</th>\n",
       "      <th>HAS_INITIATOR_CODON_CHANGE</th>\n",
       "      <th>HAS_2KB_UPSTREAM_VARIANT</th>\n",
       "      <th>HAS_COMPLEX_CHANGE_IN_TRANSCRIPT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KYW1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KYW10</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KYW100</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>KYW1000</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>KYW1001</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 98 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ID  NMUT  UNIQUE_GENES  GENE_SCORE  GENE_TET2  GENE_ASXL1  GENE_SF3B1  \\\n",
       "0     KYW1     4             4           0        0.0         0.0         0.0   \n",
       "1    KYW10     2             2           0        0.0         0.0         0.0   \n",
       "2   KYW100     2             2           0        0.0         0.0         0.0   \n",
       "3  KYW1000     5             3           0        1.0         0.0         0.0   \n",
       "4  KYW1001     6             6           2        0.0         1.0         0.0   \n",
       "\n",
       "   GENE_DNMT3A  GENE_RUNX1  GENE_SRSF2  ...  HAS_FRAMESHIFT_VARIANT  \\\n",
       "0          1.0         0.0         0.0  ...                       1   \n",
       "1          0.0         0.0         0.0  ...                       0   \n",
       "2          0.0         0.0         0.0  ...                       0   \n",
       "3          0.0         0.0         0.0  ...                       1   \n",
       "4          0.0         1.0         1.0  ...                       1   \n",
       "\n",
       "   HAS_STOP_GAINED  HAS_SPLICE_SITE_VARIANT  HAS_INFRAME_CODON_LOSS  HAS_PTD  \\\n",
       "0                1                        0                       0        0   \n",
       "1                1                        0                       0        0   \n",
       "2                1                        0                       0        0   \n",
       "3                1                        0                       0        0   \n",
       "4                1                        0                       0        0   \n",
       "\n",
       "   HAS_INFRAME_CODON_GAIN  HAS_ITD  HAS_INITIATOR_CODON_CHANGE  \\\n",
       "0                       0        1                           0   \n",
       "1                       0        0                           0   \n",
       "2                       0        0                           0   \n",
       "3                       0        0                           0   \n",
       "4                       0        0                           0   \n",
       "\n",
       "   HAS_2KB_UPSTREAM_VARIANT  HAS_COMPLEX_CHANGE_IN_TRANSCRIPT  \n",
       "0                         0                                 0  \n",
       "1                         0                                 0  \n",
       "2                         0                                 0  \n",
       "3                         0                                 0  \n",
       "4                         0                                 0  \n",
       "\n",
       "[5 rows x 98 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"----MOLECULAR TRAIN DATA----\")\n",
    "display(df_molecular_train_modified.head())\n",
    "print(\"----MOLECULAR TEST DATA----\")\n",
    "display(df_molecular_test_modified.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7856790f",
   "metadata": {},
   "source": [
    "# Running with different model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8d5557de",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_clinical_train = df_clinical_train\n",
    "x_molecular_train = df_molecular_train_modified\n",
    "x_train = pd.merge(x_clinical_train,x_molecular_train, on='ID', how='left')\n",
    "\n",
    "cols_to_exclude = ['ID', 'CENTER', 'CYTOGENETICS', 'GENE', 'EFFECT']\n",
    "features = [c for c in x_train.columns if c not in cols_to_exclude and pd.api.types.is_numeric_dtype(x_train[c])]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e02db9a",
   "metadata": {},
   "source": [
    "A. GradientBoostingSurvivalAnalysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1f662aef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Regressor</th>\n",
       "      <th>Cox Index Train</th>\n",
       "      <th>Cox Index Test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GBSA</td>\n",
       "      <td>0.774003</td>\n",
       "      <td>0.723111</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Regressor  Cox Index Train  Cox Index Test\n",
       "0      GBSA         0.774003        0.723111"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X = x_train.loc[x_train['ID'].isin(df_traget_train['ID']), features]\n",
    "y = Surv.from_dataframe('OS_STATUS', 'OS_YEARS', df_traget_train)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.125, random_state=42)\n",
    "\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "X_train[features] = imputer.fit_transform(X_train[features])\n",
    "X_test[features] = imputer.transform(X_test[features])\n",
    "\n",
    "results_GBSA = []\n",
    "model_GBSA = GradientBoostingSurvivalAnalysis(loss='coxph', n_estimators=200, random_state=42)\n",
    "\n",
    "model_GBSA.fit(X_train, y_train)\n",
    "cindex_train = concordance_index_ipcw(y_train, y_train, model_GBSA.predict(X_train), tau=7)[0]\n",
    "cindex_test = concordance_index_ipcw(y_train, y_test, model_GBSA.predict(X_test), tau=7)[0]    \n",
    "\n",
    "results_GBSA.append(['GBSA', cindex_train, cindex_test])\n",
    "df_results_GBSA = pd.DataFrame(results_GBSA, columns=['Regressor', 'Cox Index Train', 'Cox Index Test'])\n",
    "\n",
    "display(df_results_GBSA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e5fbea9",
   "metadata": {},
   "source": [
    "We run again the model but we do it without all features that have a negative permutation importance score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "dae9c931",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Regressor</th>\n",
       "      <th>Cox Index Train</th>\n",
       "      <th>Cox Index Test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GBSA</td>\n",
       "      <td>0.774206</td>\n",
       "      <td>0.732911</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Regressor  Cox Index Train  Cox Index Test\n",
       "0      GBSA         0.774206        0.732911"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "perm_imp_GBSA = permutation_importance(model_GBSA, X_test, y_test, n_repeats=1, random_state=42)\n",
    "importance_score_GBSA = perm_imp_GBSA.importances_mean\n",
    "feature_name_GBSA = X_test.columns\n",
    "\n",
    "feature_importance_GBSA = pd.DataFrame({\n",
    "    'Feature': feature_name_GBSA,\n",
    "    'Importance': importance_score_GBSA\n",
    "})\n",
    "\n",
    "feature_importance_GBSA = feature_importance_GBSA.sort_values(by='Importance', ascending=False)\n",
    "neg_feature_GBSA = feature_importance_GBSA[feature_importance_GBSA['Importance']<0]['Feature']\n",
    "\n",
    "new_features_GBSA = [f for f in features if f not in list(neg_feature_GBSA)]\n",
    "\n",
    "X = x_train.loc[x_train['ID'].isin(df_traget_train['ID']), new_features_GBSA]\n",
    "y = Surv.from_dataframe('OS_STATUS', 'OS_YEARS', df_traget_train)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.125, random_state=42)\n",
    "\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "X_train[new_features_GBSA] = imputer.fit_transform(X_train[new_features_GBSA])\n",
    "X_test[new_features_GBSA] = imputer.transform(X_test[new_features_GBSA])\n",
    "\n",
    "results_GBSA = []\n",
    "model_GBSA = GradientBoostingSurvivalAnalysis(loss='coxph', n_estimators=200, random_state=42)\n",
    "\n",
    "model_GBSA.fit(X_train, y_train)\n",
    "cindex_train = concordance_index_ipcw(y_train, y_train, model_GBSA.predict(X_train), tau=7)[0]\n",
    "cindex_test = concordance_index_ipcw(y_train, y_test, model_GBSA.predict(X_test), tau=7)[0]    \n",
    "\n",
    "results_GBSA.append(['GBSA', cindex_train, cindex_test])\n",
    "\n",
    "df_results_GBSA = pd.DataFrame(results_GBSA, columns=['Regressor', 'Cox Index Train', 'Cox Index Test'])\n",
    "display(df_results_GBSA)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "619278de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 5 candidates, totalling 10 fits\n",
      "Best params:  {'learning_rate': 0.03284055546314148, 'max_depth': 3, 'max_features': 'sqrt', 'min_samples_leaf': 42, 'n_estimators': 584, 'subsample': 0.8002200360722076}\n",
      "Score CV:  0.7280775657832169\n",
      "Score IPCW Score index  0.7323088016314836\n"
     ]
    }
   ],
   "source": [
    "model_GBSA_optimization = GradientBoostingSurvivalAnalysis(loss='coxph', random_state=42)\n",
    "\n",
    "params_GBSA = {\n",
    "    \"n_estimators\": stats.randint(100, 800),\n",
    "    \"learning_rate\": stats.uniform(0.01, 0.1),\n",
    "    \"max_depth\": stats.randint(3, 7),\n",
    "    \"min_samples_leaf\": stats.randint(10,50),\n",
    "    \"max_features\": ['sqrt', 'log2', None],\n",
    "    \"subsample\": stats.uniform(0.7, 0.2)\n",
    "}\n",
    "\n",
    "cv_GBSA = KFold(n_splits=2, shuffle=True, random_state=42)\n",
    "\n",
    "search_GBSA = RandomizedSearchCV(\n",
    "    estimator=model_GBSA_optimization,\n",
    "    param_distributions=params_GBSA,\n",
    "    n_iter=5, # My PC is very slow we only use 2 here but the best would be to us 50 or even 100\n",
    "    cv=cv_GBSA,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "search_GBSA.fit(X_train, y_train)\n",
    "best_model_GBSA = search_GBSA.best_estimator_\n",
    "score_test_GBSA = best_model_GBSA.predict(X_test)\n",
    "c_index_ipcw_GBSA = concordance_index_ipcw(y_train, y_test, score_test_GBSA, tau=7)[0]\n",
    "\n",
    "print(\"Best params: \", search_GBSA.best_params_)\n",
    "print(\"Score CV: \", search_GBSA.best_score_)\n",
    "print(\"Score IPCW Score index \", c_index_ipcw_GBSA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7683ee92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C-Index: 0.7329110981196992, model saved\n",
      "C-Index: 0.7323088016314836, model optimized saved\n"
     ]
    }
   ],
   "source": [
    "x_clinical_test = df_clinical_test\n",
    "x_molecular_test = df_molecular_test_modified\n",
    "x_test = pd.merge(x_clinical_test,x_molecular_test, on='ID', how='left')\n",
    "\n",
    "x_test[new_features_GBSA] = imputer.transform(x_test[new_features_GBSA])\n",
    "\n",
    "prediction_on_test_set_GBSA = model_GBSA.predict(x_test.loc[:,new_features_GBSA])\n",
    "prediction_on_test_set_GBSA_optimized = best_model_GBSA.predict(x_test.loc[:,new_features_GBSA])\n",
    "\n",
    "submission_GBSA = pd.Series(prediction_on_test_set_GBSA, index=x_test['ID'])\n",
    "submission_GBSA_optimized = pd.Series(prediction_on_test_set_GBSA_optimized, index=x_test['ID'])\n",
    "\n",
    "submission_normalized_GBSA = (submission_GBSA - submission_GBSA.min()) / (submission_GBSA.max() - submission_GBSA.min())\n",
    "submission_normalized_GBSA = pd.DataFrame(submission_normalized_GBSA, columns=['risk_score'])\n",
    "submission_normalized_GBSA.to_csv('result_GBSA.csv')\n",
    "print(f\"C-Index: {cindex_test}, model saved\")\n",
    "\n",
    "submission_normalized_GBSA_optimized = (submission_GBSA_optimized - submission_GBSA_optimized.min()) / (submission_GBSA_optimized.max() - submission_GBSA_optimized.min())\n",
    "submission_normalized_GBSA_optimized = pd.DataFrame(submission_normalized_GBSA_optimized, columns=['risk_score'])\n",
    "submission_normalized_GBSA_optimized.to_csv('result_GBSA_optimized.csv')\n",
    "print(f\"C-Index: {c_index_ipcw_GBSA}, model optimized saved\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f5b623c",
   "metadata": {},
   "source": [
    "B. ExtraSurvivalTrees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d63d556b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Regressor</th>\n",
       "      <th>Cox Index Train</th>\n",
       "      <th>Cox Index Test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ExtraSurvivalTrees</td>\n",
       "      <td>0.811637</td>\n",
       "      <td>0.713749</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Regressor  Cox Index Train  Cox Index Test\n",
       "0  ExtraSurvivalTrees         0.811637        0.713749"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X = x_train.loc[x_train['ID'].isin(df_traget_train['ID']), features]\n",
    "y = Surv.from_dataframe('OS_STATUS', 'OS_YEARS', df_traget_train)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.125, random_state=42)\n",
    "\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "X_train[features] = imputer.fit_transform(X_train[features])\n",
    "X_test[features] = imputer.transform(X_test[features])\n",
    "\n",
    "results_EST = []\n",
    "model_EST = ExtraSurvivalTrees(n_estimators=200, random_state=42)\n",
    "\n",
    "model_EST.fit(X_train, y_train)\n",
    "cindex_train = concordance_index_ipcw(y_train, y_train, model_EST.predict(X_train), tau=7)[0]\n",
    "cindex_test = concordance_index_ipcw(y_train, y_test, model_EST.predict(X_test), tau=7)[0]    \n",
    "\n",
    "results_EST.append(['ExtraSurvivalTrees', cindex_train, cindex_test])\n",
    "\n",
    "df_results_EST = pd.DataFrame(results_EST, columns=['Regressor', 'Cox Index Train', 'Cox Index Test']).sort_values(by='Cox Index Test', ascending=False)\n",
    "display(df_results_EST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b26e0e84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Regressor</th>\n",
       "      <th>Cox Index Train</th>\n",
       "      <th>Cox Index Test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ExtraSurvivalTrees</td>\n",
       "      <td>0.801671</td>\n",
       "      <td>0.734808</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Regressor  Cox Index Train  Cox Index Test\n",
       "0  ExtraSurvivalTrees         0.801671        0.734808"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "perm_imp_EST = permutation_importance(model_EST, X_test, y_test, n_repeats=1, random_state=42)\n",
    "importance_score_EST = perm_imp_EST.importances_mean\n",
    "feature_name_EST = X_test.columns\n",
    "\n",
    "feature_importance_EST = pd.DataFrame({\n",
    "    'Feature': feature_name_EST,\n",
    "    'Importance': importance_score_EST\n",
    "})\n",
    "\n",
    "feature_importance_EST = feature_importance_EST.sort_values(by='Importance', ascending=False)\n",
    "neg_feature_EST = feature_importance_EST[feature_importance_EST['Importance']<0]['Feature']\n",
    "\n",
    "new_features_EST = [f for f in features if f not in list(neg_feature_EST)]\n",
    "X = x_train.loc[x_train['ID'].isin(df_traget_train['ID']), new_features_EST]\n",
    "y = Surv.from_dataframe('OS_STATUS', 'OS_YEARS', df_traget_train)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.125, random_state=42)\n",
    "\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "X_train[new_features_EST] = imputer.fit_transform(X_train[new_features_EST])\n",
    "X_test[new_features_EST] = imputer.transform(X_test[new_features_EST])\n",
    "\n",
    "results_EST = []\n",
    "model_EST = ExtraSurvivalTrees(n_estimators=200, random_state=42)\n",
    "\n",
    "model_EST.fit(X_train, y_train)\n",
    "cindex_train = concordance_index_ipcw(y_train, y_train, model_EST.predict(X_train), tau=7)[0]\n",
    "cindex_test = concordance_index_ipcw(y_train, y_test, model_EST.predict(X_test), tau=7)[0]    \n",
    "\n",
    "results_EST.append(['ExtraSurvivalTrees', cindex_train, cindex_test])\n",
    "\n",
    "df_results_EST = pd.DataFrame(results_EST, columns=['Regressor', 'Cox Index Train', 'Cox Index Test'])\n",
    "display(df_results_EST)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ec598aac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 5 candidates, totalling 10 fits\n",
      "Best params:  {'bootstrap': True, 'max_depth': 20, 'max_features': 0.9, 'min_samples_leaf': 8, 'min_samples_split': 17, 'n_estimators': 607}\n",
      "Score CV:  0.7183537431222389\n",
      "Score IPCW Score index  0.7318988591661438\n"
     ]
    }
   ],
   "source": [
    "model_EST_optimization = ExtraSurvivalTrees(random_state=42)\n",
    "\n",
    "params_EST = {\n",
    "    \"n_estimators\": stats.randint(300, 800),\n",
    "    \"max_depth\": [None, 10, 20, 30],\n",
    "    \"min_samples_split\": stats.randint(4, 20),\n",
    "    \"min_samples_leaf\": stats.randint(2, 10),\n",
    "    \"max_features\": ['sqrt', 'log2', 0.5, 0.7, 0.9],\n",
    "    \"bootstrap\": [True, False]\n",
    "}\n",
    "\n",
    "cv_RSF = KFold(n_splits=2, shuffle=True, random_state=42)\n",
    "\n",
    "search_EST = RandomizedSearchCV(\n",
    "    estimator=model_EST_optimization,\n",
    "    param_distributions=params_EST,\n",
    "    n_iter=5, # My PC is very slow we only use 2 here but the best would be to us 50 or even 100\n",
    "    cv=cv_RSF,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "search_EST.fit(X_train, y_train)\n",
    "best_model_EST = search_EST.best_estimator_\n",
    "score_test_EST = best_model_EST.predict(X_test)\n",
    "c_index_ipcw_EST = concordance_index_ipcw(y_train, y_test, score_test_EST, tau=7)[0]\n",
    "\n",
    "print(\"Best params: \", search_EST.best_params_)\n",
    "print(\"Score CV: \", search_EST.best_score_)\n",
    "print(\"Score IPCW Score index \", c_index_ipcw_EST)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5e380807",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C-Index: 0.7348078282986609, model saved\n",
      "C-Index: 0.7318988591661438, model optimized saved\n"
     ]
    }
   ],
   "source": [
    "x_clinical_test = df_clinical_test\n",
    "x_molecular_test = df_molecular_test_modified\n",
    "x_test = pd.merge(x_clinical_test,x_molecular_test, on='ID', how='left')\n",
    "\n",
    "x_test[new_features_EST] = imputer.transform(x_test[new_features_EST])\n",
    "\n",
    "prediction_on_test_set_EST = model_EST.predict(x_test.loc[:,new_features_EST])\n",
    "prediction_on_test_set_EST_optimized = best_model_EST.predict(x_test.loc[:,new_features_EST])\n",
    "\n",
    "submission_EST = pd.Series(prediction_on_test_set_EST, index=x_test['ID'])\n",
    "submission_EST_optimized = pd.Series(prediction_on_test_set_EST_optimized, index=x_test['ID'])\n",
    "\n",
    "submission_normalized_EST = (submission_EST - submission_EST.min()) / (submission_EST.max() - submission_EST.min())\n",
    "submission_normalized_EST = pd.DataFrame(submission_normalized_EST, columns=['risk_score'])\n",
    "submission_normalized_EST.to_csv('result_EST.csv')\n",
    "print(f\"C-Index: {cindex_test}, model saved\")\n",
    "\n",
    "submission_normalized_EST_optimized = (submission_EST_optimized - submission_EST_optimized.min()) / (submission_EST_optimized.max() - submission_EST_optimized.min())\n",
    "submission_normalized_EST_optimized = pd.DataFrame(submission_normalized_EST_optimized, columns=['risk_score'])\n",
    "submission_normalized_EST_optimized.to_csv('result_EST_optimized.csv')\n",
    "print(f\"C-Index: {c_index_ipcw_EST}, model optimized saved\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1372bf1f",
   "metadata": {},
   "source": [
    "C. RandomSurvivalForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "51b76751",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Regressor</th>\n",
       "      <th>Cox Index Train</th>\n",
       "      <th>Cox Index Test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RSF</td>\n",
       "      <td>0.875867</td>\n",
       "      <td>0.731461</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Regressor  Cox Index Train  Cox Index Test\n",
       "0       RSF         0.875867        0.731461"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X = x_train.loc[x_train['ID'].isin(df_traget_train['ID']), features]\n",
    "y = Surv.from_dataframe('OS_STATUS', 'OS_YEARS', df_traget_train)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.125, random_state=42)\n",
    "\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "X_train[features] = imputer.fit_transform(X_train[features])\n",
    "X_test[features] = imputer.transform(X_test[features])\n",
    "\n",
    "results_RSF = []\n",
    "model_RSF = RandomSurvivalForest(n_estimators=200, random_state=42)\n",
    "\n",
    "model_RSF.fit(X_train, y_train)\n",
    "cindex_train = concordance_index_ipcw(y_train, y_train, model_RSF.predict(X_train), tau=7)[0]\n",
    "cindex_test = concordance_index_ipcw(y_train, y_test, model_RSF.predict(X_test), tau=7)[0]    \n",
    "\n",
    "results_RSF.append(['RSF', cindex_train, cindex_test])\n",
    "\n",
    "df_results_RSF = pd.DataFrame(results_RSF, columns=['Regressor', 'Cox Index Train', 'Cox Index Test']).sort_values(by='Cox Index Test', ascending=False)\n",
    "display(df_results_RSF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "1cf64041",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Regressor</th>\n",
       "      <th>Cox Index Train</th>\n",
       "      <th>Cox Index Test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RSF</td>\n",
       "      <td>0.861821</td>\n",
       "      <td>0.740343</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Regressor  Cox Index Train  Cox Index Test\n",
       "0       RSF         0.861821        0.740343"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "perm_imp_RSF = permutation_importance(model_RSF, X_test, y_test, n_repeats=1, random_state=42)\n",
    "importance_score_RSF = perm_imp_RSF.importances_mean\n",
    "feature_name_RSF = X_test.columns\n",
    "\n",
    "feature_importance_RSF = pd.DataFrame({\n",
    "    'Feature': feature_name_RSF,\n",
    "    'Importance': importance_score_RSF\n",
    "})\n",
    "\n",
    "feature_importance_RSF = feature_importance_RSF.sort_values(by='Importance', ascending=False)\n",
    "neg_feature_RSF = feature_importance_RSF[feature_importance_RSF['Importance']<0]['Feature']\n",
    "\n",
    "new_features_RSF = [f for f in features if f not in list(neg_feature_RSF)]\n",
    "X = x_train.loc[x_train['ID'].isin(df_traget_train['ID']), new_features_RSF]\n",
    "y = Surv.from_dataframe('OS_STATUS', 'OS_YEARS', df_traget_train)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.125, random_state=42)\n",
    "\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "X_train[new_features_RSF] = imputer.fit_transform(X_train[new_features_RSF])\n",
    "X_test[new_features_RSF] = imputer.transform(X_test[new_features_RSF])\n",
    "\n",
    "results_RSF = []\n",
    "model_RSF = RandomSurvivalForest(n_estimators=200, random_state=42)\n",
    "\n",
    "model_RSF.fit(X_train, y_train)\n",
    "cindex_train = concordance_index_ipcw(y_train, y_train, model_RSF.predict(X_train), tau=7)[0]\n",
    "cindex_test = concordance_index_ipcw(y_train, y_test, model_RSF.predict(X_test), tau=7)[0]    \n",
    "\n",
    "results_RSF.append(['RSF', cindex_train, cindex_test])\n",
    "\n",
    "df_results_RSF = pd.DataFrame(results_RSF, columns=['Regressor', 'Cox Index Train', 'Cox Index Test'])\n",
    "display(df_results_RSF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "1143905c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 5 candidates, totalling 10 fits\n",
      "Best params:  {'bootstrap': False, 'max_depth': 30, 'max_features': 'sqrt', 'min_samples_leaf': 5, 'min_samples_split': 13, 'n_estimators': 586}\n",
      "Score CV:  0.7207565452479878\n",
      "Score IPCW Score index  0.7368670794121454\n"
     ]
    }
   ],
   "source": [
    "model_RSF_optimization = RandomSurvivalForest(random_state=42)\n",
    "\n",
    "params_RSF = {\n",
    "    \"n_estimators\": stats.randint(200, 600),\n",
    "    \"max_depth\": [None, 10, 20, 30, 50],\n",
    "    \"min_samples_split\": stats.randint(4, 20),\n",
    "    \"min_samples_leaf\": stats.randint(2, 10),\n",
    "    \"max_features\": ['sqrt', 'log2', 0.5, 0.7],\n",
    "    \"bootstrap\": [True, False]\n",
    "}\n",
    "\n",
    "cv_RSF = KFold(n_splits=2, shuffle=True, random_state=42)\n",
    "\n",
    "search_RSF = RandomizedSearchCV(\n",
    "    estimator=model_RSF_optimization,\n",
    "    param_distributions=params_RSF,\n",
    "    n_iter=5, # My PC is very slow we only use 2 here but the best would be to us 50 or even 100\n",
    "    cv=cv_RSF,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "search_RSF.fit(X_train, y_train)\n",
    "best_model_RSF = search_RSF.best_estimator_\n",
    "score_test_RSF = best_model_RSF.predict(X_test)\n",
    "c_index_ipcw_RSF = concordance_index_ipcw(y_train, y_test, score_test_RSF, tau=7)[0]\n",
    "\n",
    "print(\"Best params: \", search_RSF.best_params_)\n",
    "print(\"Score CV: \", search_RSF.best_score_)\n",
    "print(\"Score IPCW Score index \", c_index_ipcw_RSF)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "6a6006c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C-Index: 0.7403432078630965, model saved\n",
      "C-Index: 0.7368670794121454, model optimized saved\n"
     ]
    }
   ],
   "source": [
    "x_clinical_test = df_clinical_test\n",
    "x_molecular_test = df_molecular_test_modified\n",
    "x_test = pd.merge(x_clinical_test,x_molecular_test, on='ID', how='left')\n",
    "\n",
    "x_test[new_features_RSF] = imputer.transform(x_test[new_features_RSF])\n",
    "\n",
    "prediction_on_test_set_RSF = model_RSF.predict(x_test.loc[:,new_features_RSF])\n",
    "prediction_on_test_set_RSF_optimized = best_model_RSF.predict(x_test.loc[:,new_features_RSF])\n",
    "\n",
    "submission_RSF = pd.Series(prediction_on_test_set_RSF, index=x_test['ID'])\n",
    "submission_RSF_optimized = pd.Series(prediction_on_test_set_RSF_optimized, index=x_test['ID'])\n",
    "\n",
    "submission_normalized_RSF = (submission_RSF - submission_RSF.min()) / (submission_RSF.max() - submission_RSF.min())\n",
    "submission_normalized_RSF = pd.DataFrame(submission_normalized_RSF, columns=['risk_score'])\n",
    "submission_normalized_RSF.to_csv('result_RSF.csv')\n",
    "print(f\"C-Index: {cindex_test}, model saved\")\n",
    "\n",
    "submission_normalized_RSF_optimized = (submission_RSF_optimized - submission_RSF_optimized.min()) / (submission_RSF_optimized.max() - submission_RSF_optimized.min())\n",
    "submission_normalized_RSF_optimized = pd.DataFrame(submission_normalized_RSF_optimized, columns=['risk_score'])\n",
    "submission_normalized_RSF_optimized.to_csv('result_RSF_optimized.csv')\n",
    "print(f\"C-Index: {c_index_ipcw_RSF}, model optimized saved\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
